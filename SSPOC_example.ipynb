{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Optimization for Classification Example\n",
    "\n",
    "Based on the work of Brunton, et al[<sup>1</sup>](#fn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "The strategy to be employed is as follows:\n",
    "1. Project the data to an ideal basis. Here we will use principal components analysis (PCA).\n",
    "2. Identify a maximally-discriminating projection vector to the new subspace.  Here we use linear discriminant analysis (LDA).\n",
    "3. Find the sparsest vector in the original feature space that maps to the maximally-discriminating projection vector.  Here we use convex constrained optimization.\n",
    "4. Use the sparse vector to create a measurement matrix that sparsifies the images.\n",
    "5. Train a classifier on the sparsified data.  Here we use logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data\n",
    "Load the packages required for the example.  This may take some time, as Flux requires a good deal of precompilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles, LinearAlgebra, Statistics, Convex, COSMO, StatsBase, Flux\n",
    "using Flux.Data:DataLoader\n",
    "using Flux.Losses: logitbinarycrossentropy\n",
    "using Flux: onecold, onehotbatch\n",
    "using StatsBase, PyCall\n",
    "\n",
    "const DIR = @__DIR__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pyplot object for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = pyimport(\"matplotlib.pyplot\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets for the example.  \n",
    "\n",
    "These are vectorized 64x64 pixel grayscale images of cats and dogs in column-major format (arranged as a matrix with pixels as rows and images as columns).  There are 80 images of each type, for a total of 160 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats = Float32.(readdlm(DIR*\"/SSPOC/data/cats.csv\", ','))\n",
    "dogs = Float32.(readdlm(DIR*\"/SSPOC/data/dogs.csv\", ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomize the images within classes in order to account for any bias in the original ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats = cats[:, sample(1:size(cats, 2), size(cats, 2), replace=false)]\n",
    "dogs = dogs[:, sample(1:size(dogs, 2), size(dogs, 2), replace=false)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a few example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3)\n",
    "cmap = plt.cm.gray\n",
    "for i = 1:2:5\n",
    "    ax[i].imshow(reshape(cats[:,i], (64, 64)), cmap=cmap)\n",
    "end\n",
    "for i = 2:2:6\n",
    "    ax[i].imshow(reshape(dogs[:,i], (64, 64)), cmap=cmap)\n",
    "end\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and testing sets.  \n",
    "\n",
    "The first 60 images of each type will be used for training.  The remaining 20 of each type will be for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train1 = [cats[:,1:60] dogs[:,1:60]];\n",
    "test1 = [cats[:,61:end] dogs[:,61:end]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the eigenrepresentation\n",
    "Compute the PCA to get the eigenrepresentation.  The left singular vectors now form an orthonormal basis for the column space of the data.  This means that the new coordinate system can be used to encode correlation between images.  Conversely, the right singular vectors form an orthonormal basis for the row space, which is not what we want to use here (you can see this for yourself by projecting the original data onto the right singular subspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n, m = size(train1)\n",
    "## centering matrix\n",
    "C = I(m) - (1/m) * ones(m,m)\n",
    "train_centered = train1 * C\n",
    "U, λ, V = svd(train_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loadings of each feature onto individual images is given by the $\\mathbf{V}$ (right singular vectors) matrix.  The loadings for the first 3 modes of the $\\mathbf{V}$ matrix are shown for each image type.  It can be seen that certain modes capture more separability than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbin = -.25:.05:.25\n",
    "fig, ax = plt.subplots(1,3)\n",
    "for i = 1:3\n",
    "    ax[i].hist(V[1:80,i], color=\"red\", bins=xbin, label=\"cats\")\n",
    "    ax[i].hist(V[81:end, i], color=\"blue\", bins=xbin, label=\"dogs\")\n",
    "end\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the eigenvalues to identify a reasonable reduced rank in a principled, albeit unrigorous, way.  The idea is to use a minimal-rank representation that still adequately encodes the data.  Our assumption that many complex phenomena exhibit low-rank structure is depicted graphically by the elbow shape of the plot.  This means that, in this case, beyond around the first 30 to 40 eigenvalues, the remaining 80 to 90 contribute (relatively) little to the structure, and can be truncated with minimal loss of information.  Mathematically rigorous methods for identifying an optimal rank exist, but are beyond the scope of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(1:length(λ), λ)\n",
    "plt.xlabel(\"Eigenvalue index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "We can now choose a reduced-rank basis Ψ for the subspace (here we somewhat arbitrarily choose 40).  Recall that the left singular matrix, $\\mathbf{U}$, captures the correlations between images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ψ = U[:,1:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modes of this space represent the dominant features across images.  We can view these by reshaping the columns of $\\Psi$.  The pictures of the 6 leading eigenfaces suggest that the shape of cats' ears are highly important.  This is intuitive, as dogs generally exhibit a more diverse set of phenotpyes than cats (cats normally never have floppy ears)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3)\n",
    "cmap = plt.cm.gray\n",
    "for i = 1:2:5\n",
    "    ax[i].imshow(reshape(Ψ[:,i], (64, 64)), cmap=cmap)\n",
    "end\n",
    "for i = 2:2:6\n",
    "    ax[i].imshow(reshape(Ψ[:,i], (64, 64)), cmap=cmap)\n",
    "end\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projecting the original data onto the new space will transform the images into their fundamental representation, $\\mathbf{\\tilde{X}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X̃ = Ψ' * train1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute the maximally discriminating vector using LDA\n",
    "We can use linear discriminant analysis (LDA) to find a vector that maximally discriminates between the two image classes.  Really, any statistical method can be used here, but LDA is straightforward, interpretable, and very effective for this problem.\n",
    "\n",
    "### Compute between-classes scatter matrix\n",
    "Since there are only two classes and they are balanced, the between-class scatter matrix is given by $\\mathbf{S_B} = (\\mathbf{\\mu}_1 - \\mathbf{\\mu_2})(\\mathbf{\\mu}_1 - \\mathbf{\\mu}_2)^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "μ1 = mean(X̃[:, 1:60], dims=2)\n",
    "μ2 = mean(X̃[:,61:end], dims=2)\n",
    "Sb = (μ2 - μ1) * (μ2 - μ1)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the within-classes scatter matrix\n",
    "The within-class scatter is given by $\\mathbf{S_W} = (\\mathbf{X_1} - \\mathbf{\\mu}_1)(\\mathbf{X_2} - \\mathbf{\\mu}_2)^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function scatter_matrix(data, mu)\n",
    "    (data - mu .* ones(size(data))) * (data - mu .* ones(size(data)))'\n",
    "end\n",
    "## within-classes scatter Sw\n",
    "Σ1 = scatter_matrix(X̃[:,1:60], μ1)\n",
    "Σ2 = scatter_matrix(X̃[:,61:end], μ2)\n",
    "Sw = Σ1 + Σ2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the projection matrix and get the maximum-discriminating projection vector\n",
    "\n",
    "We want to find the projection that maximizes the between-class scatter, $\\mathbf{S_B}$, with respect to the within-class scatter, $\\mathbf{S_W}$.  The Rayleigh quotient\n",
    "\n",
    "$$\\hat{\\mathbf{u}} =\\underset{\\mathbf{u}}{\\operatorname{arg max}}\\dfrac{\\mathbf{u}^T\\mathbf{S_Bu}}{\\mathbf{u}^T\\mathbf{S_Wu}}$$\n",
    "\n",
    "can be solved as a generalized eigenvalue problem\n",
    "\n",
    "$$\\mathbf{S_B}\\mathbf{U} = \\mathbf{\\Lambda} \\mathbf{S_WU}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Λ, W = eigen(Sb, Sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose eigenvector $\\mathbf{w}$ corresponding to the leading eigenvalue (this represents the maximally discriminating projection vector in the new subspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Λ = reverse(Λ)\n",
    "W = reverse(W, dims=2)\n",
    "w = real(W[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Find a sparse vector in original space that maps to $\\mathbf{w}$\n",
    "\n",
    "$\\mathbf{s}$ (the maximally sparse vector in original space that maps to $\\mathbf{w}$) can be found by solving the optimizaton problem\n",
    "\n",
    "$$\\hat{\\mathbf{s}} =\\underset{\\mathbf{s}}{\\operatorname{arg min}}\\lvert\\lvert \\mathbf{s}\\rvert\\rvert_0 {\\text{  subject to  }} \\mathbf{w} = \\Psi \\mathbf{s}$$\n",
    "    \n",
    "where $\\lvert\\lvert \\cdot \\rvert\\rvert_0$ is the cardinality.\n",
    "This can be relaxed to \n",
    "\n",
    "$$\\hat{\\mathbf{s}} =\\underset{\\mathbf{s}}{\\operatorname{arg min}}\\lvert\\lvert \\mathbf{s}\\rvert\\rvert_1 {\\text{  subject to  }} \\mathbf{w} = \\Psi \\mathbf{s}$$\n",
    "\n",
    "provided that the nonzero elements of $\\mathbf{s}$ are incoherent with respect to $\\Psi$.  This is a reasonble assumption since the nonzero elements correspond to pixels in the original space.  However, the L1 relaxation of the objective function is a probabilistic assumption.  We can say there is a high probability of it holding, but there is no mathematical guarantee.\n",
    "\n",
    "When using the solver, note that a good approximation can still be achieved without convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = size(train1, 1)\n",
    "s = Variable(n)\n",
    "objective = norm(s,1)\n",
    "constraint = Ψ' * s == w;\n",
    "solver = COSMO.Optimizer;\n",
    "problem = minimize(objective, constraint);\n",
    "solve!(problem, solver);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check linear separability imposed by sparse vector $\\hat{\\mathbf{s}}$.  The $y$-axis represents the loadings and images are arranged along the $x$-axis (1-60 are cats and 61-120 are dogs).  The discrimination function lies at $y = 0$, so the values for cats and dogs should be mostly of opposite sign.  Results may vary across runs, which highlights the importance of cross-validation in actual practice (recall the above statement concerning the probabalistic nature of the underlying assumptions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ŝ = s.value[:]\n",
    "sep = (Ψ' * ŝ)' * (Ψ' * train1)\n",
    "plt.bar(1:length(sep), sep)\n",
    "plt.xlabel(\"Images (cats=1-60, dogs=61-120)\")\n",
    "plt.ylabel(\"Loadings\")\n",
    "plt.show()\n",
    "StatsBase.describe(ŝ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the 20 pixels with the largest value.  This is an arbitrary decision made for demonstration purposes.  A principled approach would use cross-validation to identify an optimal value.  Here, the purpose is to demonstrate that a very small portion of the original feature space can produce relatively good results on a statistical learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh = abs(ŝ[reverse(sortperm(abs.(ŝ)))[21]])\n",
    "C = abs.(ŝ) .> thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify how many pixels will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that less than 0.5% of the original pixels will be used for the classification task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train a logistic regression classifier to use the sparse image\n",
    "\n",
    "Create a measurement matrix, $\\Phi$, by creating a square matrix with the desired pixel indices on the diagonal.  This will serve to \"select\" the maximally-discriminating pixels we care about for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Φ = Diagonal(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data with z score transform to improve the stability and performance of the model (since the pixel values range from 0 to 255, there are no extreme outliers requiring more advanced techniques)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt = StatsBase.fit(ZScoreTransform, train1, dims=2)\n",
    "StatsBase.transform!(dt, train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsify the original data with the measurement matrix, using the measurement matrix to send all but the imprtant pixels to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = Φ * train1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show which pixels will be used in a few example images. The third image is of the leading eigenface, to provide context as to the space which was used in determining pixel location.  Notice pixels capture certain features of the animals' faces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sparse_pixels = deepcopy(cats[:, 36])\n",
    "dog_sparse_pixels = deepcopy(dogs[:, 36])\n",
    "eig_sparse_pixels = deepcopy(Ψ[:,1])\n",
    "cat_sparse_pixels[C] .= NaN\n",
    "eig_sparse_pixels[C] .= NaN\n",
    "dog_sparse_pixels[C] .= NaN\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "cmap = plt.cm.gray\n",
    "cmap.set_bad((1, 0, 0, 1))\n",
    "ax1.imshow(reshape(cat_sparse_pixels, (64,64)), cmap=cmap)\n",
    "ax3.imshow(reshape(eig_sparse_pixels, (64,64)), cmap=cmap)\n",
    "ax2.imshow(reshape(dog_sparse_pixels, (64,64)), cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create labels for the images and prepare the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Int.(vcat(ones(60), zeros(60)))\n",
    "l = onehotbatch(labels, [0, 1])\n",
    "train = DataLoader((y, l), batchsize=32);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a logistic regression model for the binary classification task.  In principle, any classification method can be used here.  Logistic regression was chosen for its simplicity, given that there are only 2 classes.  Also note that since sparsifying the data with the measurement matrix selects features similar to L1 regularization, no explicit regularizer will be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "function loss(x, y)\n",
    "    logitbinarycrossentropy(m(x), y)\n",
    "end\n",
    "opt = ADADelta(.5)\n",
    "m = Dense(4096, 2)\n",
    "# burn-in model\n",
    "m(rand(Float32, 4096))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train for 100 epochs of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Starting training...\"\n",
    "for epoch in 1:100\n",
    "    Flux.train!(loss, params(m), train, opt)\n",
    "    if mod(epoch, 10) == 0\n",
    "        @info \"Epoch \" * string(epoch) * \" done.\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test on the witheld data\n",
    "\n",
    "Prepare test data and test for accuracy. Use the cross-validated approach below for an average across subsamples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = [cats[:,61:end] dogs[:,61:end]]\n",
    "StatsBase.transform!(dt, test1)\n",
    "y_test = Φ * test1\n",
    "labels_test = Int.(vcat(ones(20), zeros(20)))\n",
    "mean(onecold(sigmoid.(m(y_test)), [0,1]) .== labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Validated Results\n",
    "\n",
    "Here, we use simple random subsampling cross-validation to obtain an averaged result that mitigates the effect of the small sample size.  You should achieve around 80% accuracy or higher (although not guaranteed as already noted), which is quite remarkable in light of the fact that only 20 pixels were used on just 120 crudely-preprocessed images for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats = Float32.(readdlm(\"SSPOC/data/cats.csv\", ','))\n",
    "dogs = Float32.(readdlm(\"SSPOC/data/dogs.csv\", ','))\n",
    "\n",
    "function run_demo(cats, dogs, samples, rank, pixels)\n",
    "    @info \"Starting cross-validation on \" * string(samples) * \" samples...\"\n",
    "    out=zeros(samples)\n",
    "    num_err = 0\n",
    "    for i = 1:samples\n",
    "        @label start\n",
    "        cats_copy = deepcopy(cats)[:, sample(1:size(cats, 2), size(cats, 2), replace=false)];\n",
    "        dogs_copy = deepcopy(dogs)[:, sample(1:size(dogs, 2), size(dogs, 2), replace=false)];\n",
    "\n",
    "        # create training and testing sets (.74, .25)\n",
    "        train1 = [cats_copy[:,1:60] dogs_copy[:,1:60]];\n",
    "        test1 = [cats_copy[:,61:end] dogs_copy[:,61:end]];\n",
    "\n",
    "        # compute PCA and project data to get eigenrepresentation X̃\n",
    "        mean_tr = mean(train1, dims=2);\n",
    "        train_centered = train1 - mean_tr * ones(1, size(train1, 2));\n",
    "        U, S, V = svd(train_centered)\n",
    "        Ψ = U[:,1:rank];\n",
    "        X̃ = Ψ' * train1;\n",
    "\n",
    "        # compute maximally discriminating component using LDA\n",
    "        ## between-classes scatter Sb\n",
    "        μ1 = mean(X̃[:, 1:60], dims=2);\n",
    "        μ2 = mean(X̃[:,61:end], dims=2);\n",
    "        Sb = (μ2 - μ1) * (μ2 - μ1)';\n",
    "\n",
    "        function scatter_matrix(data, mu)\n",
    "            (data - mu .* ones(size(data))) * (data - mu .* ones(size(data)))'\n",
    "        end\n",
    "        ## within-classes scatter Sw\n",
    "        Σ1 = scatter_matrix(X̃[:,1:60], μ1);\n",
    "        Σ2 = scatter_matrix(X̃[:,61:end], μ2);\n",
    "        Sw = Σ1 + Σ2;\n",
    "\n",
    "        # generalized eigenvalue decomposition to get projection matrix W\n",
    "        Λ, W = eigen(Sb, Sw);\n",
    "        ## choose eigenvector corresponding to largest eigenvalue w (this represents the maximally discriminating projection vector in the new subspace)\n",
    "        Λ = reverse(real.(Λ));\n",
    "        W = reverse(W, dims=2);\n",
    "        w = real(W[:,1])\n",
    "\n",
    "        # solve for S (this is the maximally sparse vector in original space that when projected to subspace approximates w)\n",
    "        n = size(train1, 1)\n",
    "        s = Variable(n)\n",
    "        objective = norm(s,1)\n",
    "        constraint = Ψ' * s == w;\n",
    "        solver = COSMO.Optimizer;\n",
    "        problem = minimize(objective, constraint);\n",
    "        solve!(problem, solver, silent_solver=true)\n",
    "        if isnothing(s.value)\n",
    "            @warn \"Encountered a numerical error during optimization!  Repeating sample...\"\n",
    "            num_err += 1\n",
    "            @goto start\n",
    "        end\n",
    "        ŝ = s.value[:] \n",
    "        thresh = abs(ŝ[reverse(sortperm(abs.(ŝ)))[pixels + 1]])\n",
    "        C = abs.(ŝ) .> thresh;\n",
    "        \n",
    "        # create measurement matrix\n",
    "        Φ = Diagonal(C);\n",
    "\n",
    "        # scale data (z score transform)\n",
    "        dt = StatsBase.fit(ZScoreTransform, train1, dims=2);\n",
    "        StatsBase.transform!(dt, train1);\n",
    "\n",
    "        # sparsify original data with measurement matrix\n",
    "        y = Φ * train1;\n",
    "\n",
    "        # create labels\n",
    "        labels = Int.(vcat(ones(60), zeros(60)))\n",
    "        l = onehotbatch(labels, [0, 1]);\n",
    "\n",
    "        # prepare data for NN\n",
    "        train = DataLoader((y, l));\n",
    "\n",
    "        # build logistic regression model with L1 regularization\n",
    "\n",
    "        function loss(x, y)\n",
    "            logitbinarycrossentropy(m(x), y)\n",
    "        end\n",
    "\n",
    "        # optimizer\n",
    "        opt = ADADelta(.5)\n",
    "        #opt = ADAM(1e-3)\n",
    "        m = Dense(4096, 2)\n",
    "        # train for 100 epochs\n",
    "        for epoch in 1:100\n",
    "            Flux.train!(loss, params(m), train, opt)\n",
    "        end\n",
    "\n",
    "        # prepare test data\n",
    "        StatsBase.transform!(dt, test1);\n",
    "        y_test = Φ * test1;\n",
    "        labels_test = Int.(vcat(ones(20), zeros(20)));\n",
    "\n",
    "        out[i] = mean(onecold(sigmoid.(m(y_test)), [0,1]) .== labels_test)\n",
    "        @info \"Sample \"*string(i)*\" accuracy: \"*string(out[i])\n",
    "    end\n",
    "    out_text = num_err == 1 ? \" sample\" : \" samples\"\n",
    "    @info string(num_err) * out_text * \" repeated due to numerical errors.\"\n",
    "return \"Mean accuracy: \" * string(sum(out)/(samples))\n",
    "end\n",
    "run_demo(cats, dogs, 10, 40, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"fn1\">B. W. Brunton, S. L. Brunton, J. L. Proctor, J. N. Kutz. Sparse sensor placement optimization for classification.  *SIAM Journal on Applied Mathematics*, 76(5):2099-2122, 2016.</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia_SSPOC_demo 1.5.2",
   "language": "julia",
   "name": "julia_sspoc_demo-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
